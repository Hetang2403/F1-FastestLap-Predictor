{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d884c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading: f:\\Personal Projects\\F1-FastestLap-Predictor\\outputs\\f1_features_weather_enhanced.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hetan\\AppData\\Local\\Temp\\ipykernel_33272\\2926272208.py:72: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  drv_hist = df.groupby(\"driverId\", group_keys=False).apply(\n",
      "C:\\Users\\hetan\\AppData\\Local\\Temp\\ipykernel_33272\\2926272208.py:84: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  team_hist = df.groupby(\"constructorId\", group_keys=False).apply(\n",
      "C:\\Users\\hetan\\AppData\\Local\\Temp\\ipykernel_33272\\2926272208.py:99: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  track_hist = df.groupby([\"driverId\",\"circuitId\"], group_keys=False).apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved historical feature table -> f:\\Personal Projects\\F1-FastestLap-Predictor\\outputs\\f1_features_history_v1.csv\n",
      "Rows: 11041 | Cols: 58\n",
      "\n",
      "=== Historical Model (no leakage) ===\n",
      "R²   : 0.006\n",
      "MAE  : 1.945 s (gap to fastest)\n",
      "RMSE : 9.349 s (gap to fastest)\n",
      "\n",
      "✅ Saved model -> f:\\Personal Projects\\F1-FastestLap-Predictor\\models\\rf_model_delta_hist_v1.joblib\n"
     ]
    }
   ],
   "source": [
    "# 5_History_Features_and_Model.ipynb  —  Step 3: add historical features (no leakage)\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Paths\n",
    "# -------------------------------------------------------------------\n",
    "ROOT = Path.cwd()\n",
    "if not (ROOT / \"outputs\").exists():\n",
    "    ROOT = ROOT.parent\n",
    "DATA_IN  = ROOT / \"outputs\" / \"f1_features_weather_enhanced.csv\"   # your current merged table\n",
    "DATA_OUT = ROOT / \"outputs\" / \"f1_features_history_v1.csv\"\n",
    "MODEL_OUT = ROOT / \"models\" / \"rf_model_delta_hist_v1.joblib\"\n",
    "\n",
    "print(f\"Reading: {DATA_IN}\")\n",
    "df = pd.read_csv(DATA_IN)\n",
    "\n",
    "# Basic sanity\n",
    "must_have = [\"raceId\",\"driverId\",\"circuitId\",\"year\",\"round\"]\n",
    "for c in must_have:\n",
    "    if c not in df.columns:\n",
    "        raise ValueError(f\"Missing required column '{c}' in {DATA_IN}\")\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Target construction (NO leakage):\n",
    "# - Compute per-race fastest lap (seconds) and define delta_s as\n",
    "#   (driver's best lap - race fastest lap).\n",
    "# - This target is for *this* race, so OK to compute from current row.\n",
    "#   We will drop lap-time columns from features later.\n",
    "# -------------------------------------------------------------------\n",
    "if \"bestLaps_s\" not in df.columns:\n",
    "    raise ValueError(\"Column 'bestLaps_s' not found. We need it to define the target delta_s.\")\n",
    "\n",
    "race_fast = df.groupby(\"raceId\")[\"bestLaps_s\"].transform(\"min\")\n",
    "df[\"delta_s\"] = df[\"bestLaps_s\"] - race_fast\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Historical (lagged) features\n",
    "# RULE: Everything must be computed from the PAST.\n",
    "# We sort chronologically and always .shift(1) before rolling/expanding.\n",
    "# -------------------------------------------------------------------\n",
    "df = df.sort_values([\"year\",\"round\",\"raceId\",\"driverId\"]).reset_index(drop=True)\n",
    "\n",
    "def rolling_feat(g, src, windows, prefix):\n",
    "    \"\"\"\n",
    "    Build shifted rolling stats for series 'src' in group g.\n",
    "    Returns DataFrame with new columns (mean/std for each window).\n",
    "    \"\"\"\n",
    "    out = pd.DataFrame(index=g.index)\n",
    "    s = g[src].shift(1)  # shift to ensure we only use past info\n",
    "    for w in windows:\n",
    "        out[f\"{prefix}_mean_{w}\"] = s.rolling(w, min_periods=1).mean()\n",
    "        out[f\"{prefix}_std_{w}\"]  = s.rolling(w, min_periods=1).std()\n",
    "    # long-term expanding mean (all history)\n",
    "    out[f\"{prefix}_mean_exp\"] = s.expanding(min_periods=1).mean()\n",
    "    return out\n",
    "\n",
    "# ---- 1) Driver rolling history on delta_s\n",
    "windows = [3, 5, 10]\n",
    "\n",
    "drv_hist = df.groupby(\"driverId\", group_keys=False).apply(\n",
    "    lambda g: rolling_feat(g, src=\"delta_s\", windows=windows, prefix=\"drv_delta\")\n",
    ")\n",
    "df = pd.concat([df, drv_hist], axis=1)\n",
    "\n",
    "# Driver experience = how many prior starts\n",
    "df[\"drv_starts\"] = (\n",
    "    df.groupby(\"driverId\").cumcount()\n",
    ")\n",
    "\n",
    "# ---- 2) Constructor rolling history on delta_s (needs constructorId in table)\n",
    "if \"constructorId\" in df.columns:\n",
    "    team_hist = df.groupby(\"constructorId\", group_keys=False).apply(\n",
    "        lambda g: rolling_feat(g, src=\"delta_s\", windows=windows, prefix=\"team_delta\")\n",
    "    )\n",
    "    df = pd.concat([df, team_hist], axis=1)\n",
    "\n",
    "    # driver vs team form: driver's expanding mean minus team's expanding mean (both lagged)\n",
    "    df[\"drv_delta_mean_exp_shift1\"]  = df.groupby(\"driverId\")[\"delta_s\"].shift(1).expanding().mean().reset_index(level=0, drop=True)\n",
    "    df[\"team_delta_mean_exp_shift1\"] = df.groupby(\"constructorId\")[\"delta_s\"].shift(1).expanding().mean().reset_index(level=0, drop=True)\n",
    "    df[\"drv_minus_team_form\"] = df[\"drv_delta_mean_exp_shift1\"] - df[\"team_delta_mean_exp_shift1\"]\n",
    "    df.drop(columns=[\"drv_delta_mean_exp_shift1\",\"team_delta_mean_exp_shift1\"], inplace=True, errors=\"ignore\")\n",
    "else:\n",
    "    print(\"constructorId not found — skipping team features.\")\n",
    "    df[\"drv_minus_team_form\"] = np.nan\n",
    "\n",
    "# ---- 3) Track-specific (driver at the same circuit) history on delta_s\n",
    "track_hist = df.groupby([\"driverId\",\"circuitId\"], group_keys=False).apply(\n",
    "    lambda g: rolling_feat(g, src=\"delta_s\", windows=[3,5], prefix=\"drv_track_delta\")\n",
    ")\n",
    "df = pd.concat([df, track_hist], axis=1)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Optional: historical features from grid/qualifying (lagged only!)\n",
    "# These are safe as history; we will *not* use current race's grid/qual directly as-is.\n",
    "# -------------------------------------------------------------------\n",
    "for col in [c for c in [\"grid\",\"qual_best_s\"] if c in df.columns]:\n",
    "    df[f\"{col}_hist_mean_5\"] = (\n",
    "        df.groupby(\"driverId\")[col]\n",
    "          .shift(1)    # past only\n",
    "          .rolling(5, min_periods=1).mean()\n",
    "    )\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Save enriched dataset (useful to inspect / iterate)\n",
    "# -------------------------------------------------------------------\n",
    "df.to_csv(DATA_OUT, index=False)\n",
    "print(f\"Saved historical feature table -> {DATA_OUT}\")\n",
    "print(\"Rows:\", len(df), \"| Cols:\", df.shape[1])\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Train a clean model:\n",
    "# - Drop target leak columns from X (any lap-time columns for current race)\n",
    "# - Keep historical (lagged) columns we just built\n",
    "# - Simple RF baseline to verify signal emerges (>0 R² ideally)\n",
    "# -------------------------------------------------------------------\n",
    "drop_now = [\n",
    "    # columns that are direct outcomes of the *current* race:\n",
    "    \"bestLaps_s\", \"bestLap_ms\", \"f1_rank\", \"fl_avg_speed_kph\", \"finish_pos\", \"fl_rank\",\n",
    "    # identifiers we never want to predict on\n",
    "    \"raceId\",\n",
    "    # obvious text cols if present\n",
    "    \"drivers_name\", \"gp_name\", \"circuit_name\", \"date\"\n",
    "]\n",
    "\n",
    "X = df.drop(columns=[c for c in drop_now if c in df.columns], errors=\"ignore\")\n",
    "y = df[\"delta_s\"].astype(float)\n",
    "\n",
    "# Choose categorical vs numeric\n",
    "cat_cols = []\n",
    "if \"country\" in X.columns:\n",
    "    cat_cols.append(\"country\")\n",
    "\n",
    "# safe numerics = all numeric except the target\n",
    "num_cols = [c for c in X.columns if c != \"delta_s\" and pd.api.types.is_numeric_dtype(X[c])]\n",
    "\n",
    "# Remove any remaining columns that equal y (just in case)\n",
    "num_cols = [c for c in num_cols if c != \"delta_s\"]\n",
    "\n",
    "# Build preprocessing\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols),\n",
    "        (\"num\", \"passthrough\", num_cols),\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    ")\n",
    "\n",
    "# Split (simple holdout; later we can do GroupKFold per race)\n",
    "X_model = X[cat_cols + num_cols].copy()\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_model, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "rf = RandomForestRegressor(\n",
    "    n_estimators=400,\n",
    "    max_depth=None,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "pipe = Pipeline(steps=[(\"pre\", preprocess), (\"rf\", rf)])\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "pred = pipe.predict(X_test)\n",
    "r2   = r2_score(y_test, pred)\n",
    "mae  = mean_absolute_error(y_test, pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, pred))\n",
    "\n",
    "print(\"\\n=== Historical Model (no leakage) ===\")\n",
    "print(f\"R²   : {r2:0.3f}\")\n",
    "print(f\"MAE  : {mae:0.3f} s (gap to fastest)\")\n",
    "print(f\"RMSE : {rmse:0.3f} s (gap to fastest)\")\n",
    "\n",
    "MODEL_OUT.parent.mkdir(parents=True, exist_ok=True)\n",
    "joblib.dump(pipe, MODEL_OUT)\n",
    "print(f\"\\n✅ Saved model -> {MODEL_OUT}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
