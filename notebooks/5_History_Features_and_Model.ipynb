{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d884c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading: f:\\Personal Projects\\F1-FastestLap-Predictor\\outputs\\f1_features_weather_enhanced.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hetan\\AppData\\Local\\Temp\\ipykernel_33272\\2926272208.py:72: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  drv_hist = df.groupby(\"driverId\", group_keys=False).apply(\n",
      "C:\\Users\\hetan\\AppData\\Local\\Temp\\ipykernel_33272\\2926272208.py:84: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  team_hist = df.groupby(\"constructorId\", group_keys=False).apply(\n",
      "C:\\Users\\hetan\\AppData\\Local\\Temp\\ipykernel_33272\\2926272208.py:99: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  track_hist = df.groupby([\"driverId\",\"circuitId\"], group_keys=False).apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved historical feature table -> f:\\Personal Projects\\F1-FastestLap-Predictor\\outputs\\f1_features_history_v1.csv\n",
      "Rows: 11041 | Cols: 58\n",
      "\n",
      "=== Historical Model (no leakage) ===\n",
      "R²   : 0.006\n",
      "MAE  : 1.945 s (gap to fastest)\n",
      "RMSE : 9.349 s (gap to fastest)\n",
      "\n",
      "✅ Saved model -> f:\\Personal Projects\\F1-FastestLap-Predictor\\models\\rf_model_delta_hist_v1.joblib\n"
     ]
    }
   ],
   "source": [
    "# 5_History_Features_and_Model.ipynb  —  Step 3: add historical features (no leakage)\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Paths\n",
    "# -------------------------------------------------------------------\n",
    "ROOT = Path.cwd()\n",
    "if not (ROOT / \"outputs\").exists():\n",
    "    ROOT = ROOT.parent\n",
    "DATA_IN  = ROOT / \"outputs\" / \"f1_features_weather_enhanced.csv\"   # your current merged table\n",
    "DATA_OUT = ROOT / \"outputs\" / \"f1_features_history_v1.csv\"\n",
    "MODEL_OUT = ROOT / \"models\" / \"rf_model_delta_hist_v1.joblib\"\n",
    "\n",
    "print(f\"Reading: {DATA_IN}\")\n",
    "df = pd.read_csv(DATA_IN)\n",
    "\n",
    "# Basic sanity\n",
    "must_have = [\"raceId\",\"driverId\",\"circuitId\",\"year\",\"round\"]\n",
    "for c in must_have:\n",
    "    if c not in df.columns:\n",
    "        raise ValueError(f\"Missing required column '{c}' in {DATA_IN}\")\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Target construction (NO leakage):\n",
    "# - Compute per-race fastest lap (seconds) and define delta_s as\n",
    "#   (driver's best lap - race fastest lap).\n",
    "# - This target is for *this* race, so OK to compute from current row.\n",
    "#   We will drop lap-time columns from features later.\n",
    "# -------------------------------------------------------------------\n",
    "if \"bestLaps_s\" not in df.columns:\n",
    "    raise ValueError(\"Column 'bestLaps_s' not found. We need it to define the target delta_s.\")\n",
    "\n",
    "race_fast = df.groupby(\"raceId\")[\"bestLaps_s\"].transform(\"min\")\n",
    "df[\"delta_s\"] = df[\"bestLaps_s\"] - race_fast\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Historical (lagged) features\n",
    "# RULE: Everything must be computed from the PAST.\n",
    "# We sort chronologically and always .shift(1) before rolling/expanding.\n",
    "# -------------------------------------------------------------------\n",
    "df = df.sort_values([\"year\",\"round\",\"raceId\",\"driverId\"]).reset_index(drop=True)\n",
    "\n",
    "def rolling_feat(g, src, windows, prefix):\n",
    "    \"\"\"\n",
    "    Build shifted rolling stats for series 'src' in group g.\n",
    "    Returns DataFrame with new columns (mean/std for each window).\n",
    "    \"\"\"\n",
    "    out = pd.DataFrame(index=g.index)\n",
    "    s = g[src].shift(1)  # shift to ensure we only use past info\n",
    "    for w in windows:\n",
    "        out[f\"{prefix}_mean_{w}\"] = s.rolling(w, min_periods=1).mean()\n",
    "        out[f\"{prefix}_std_{w}\"]  = s.rolling(w, min_periods=1).std()\n",
    "    # long-term expanding mean (all history)\n",
    "    out[f\"{prefix}_mean_exp\"] = s.expanding(min_periods=1).mean()\n",
    "    return out\n",
    "\n",
    "# ---- 1) Driver rolling history on delta_s\n",
    "windows = [3, 5, 10]\n",
    "\n",
    "drv_hist = df.groupby(\"driverId\", group_keys=False).apply(\n",
    "    lambda g: rolling_feat(g, src=\"delta_s\", windows=windows, prefix=\"drv_delta\")\n",
    ")\n",
    "df = pd.concat([df, drv_hist], axis=1)\n",
    "\n",
    "# Driver experience = how many prior starts\n",
    "df[\"drv_starts\"] = (\n",
    "    df.groupby(\"driverId\").cumcount()\n",
    ")\n",
    "\n",
    "# ---- 2) Constructor rolling history on delta_s (needs constructorId in table)\n",
    "if \"constructorId\" in df.columns:\n",
    "    team_hist = df.groupby(\"constructorId\", group_keys=False).apply(\n",
    "        lambda g: rolling_feat(g, src=\"delta_s\", windows=windows, prefix=\"team_delta\")\n",
    "    )\n",
    "    df = pd.concat([df, team_hist], axis=1)\n",
    "\n",
    "    # driver vs team form: driver's expanding mean minus team's expanding mean (both lagged)\n",
    "    df[\"drv_delta_mean_exp_shift1\"]  = df.groupby(\"driverId\")[\"delta_s\"].shift(1).expanding().mean().reset_index(level=0, drop=True)\n",
    "    df[\"team_delta_mean_exp_shift1\"] = df.groupby(\"constructorId\")[\"delta_s\"].shift(1).expanding().mean().reset_index(level=0, drop=True)\n",
    "    df[\"drv_minus_team_form\"] = df[\"drv_delta_mean_exp_shift1\"] - df[\"team_delta_mean_exp_shift1\"]\n",
    "    df.drop(columns=[\"drv_delta_mean_exp_shift1\",\"team_delta_mean_exp_shift1\"], inplace=True, errors=\"ignore\")\n",
    "else:\n",
    "    print(\"constructorId not found — skipping team features.\")\n",
    "    df[\"drv_minus_team_form\"] = np.nan\n",
    "\n",
    "# ---- 3) Track-specific (driver at the same circuit) history on delta_s\n",
    "track_hist = df.groupby([\"driverId\",\"circuitId\"], group_keys=False).apply(\n",
    "    lambda g: rolling_feat(g, src=\"delta_s\", windows=[3,5], prefix=\"drv_track_delta\")\n",
    ")\n",
    "df = pd.concat([df, track_hist], axis=1)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Optional: historical features from grid/qualifying (lagged only!)\n",
    "# These are safe as history; we will *not* use current race's grid/qual directly as-is.\n",
    "# -------------------------------------------------------------------\n",
    "for col in [c for c in [\"grid\",\"qual_best_s\"] if c in df.columns]:\n",
    "    df[f\"{col}_hist_mean_5\"] = (\n",
    "        df.groupby(\"driverId\")[col]\n",
    "          .shift(1)    # past only\n",
    "          .rolling(5, min_periods=1).mean()\n",
    "    )\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Save enriched dataset (useful to inspect / iterate)\n",
    "# -------------------------------------------------------------------\n",
    "df.to_csv(DATA_OUT, index=False)\n",
    "print(f\"Saved historical feature table -> {DATA_OUT}\")\n",
    "print(\"Rows:\", len(df), \"| Cols:\", df.shape[1])\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Train a clean model:\n",
    "# - Drop target leak columns from X (any lap-time columns for current race)\n",
    "# - Keep historical (lagged) columns we just built\n",
    "# - Simple RF baseline to verify signal emerges (>0 R² ideally)\n",
    "# -------------------------------------------------------------------\n",
    "drop_now = [\n",
    "    # columns that are direct outcomes of the *current* race:\n",
    "    \"bestLaps_s\", \"bestLap_ms\", \"f1_rank\", \"fl_avg_speed_kph\", \"finish_pos\", \"fl_rank\",\n",
    "    # identifiers we never want to predict on\n",
    "    \"raceId\",\n",
    "    # obvious text cols if present\n",
    "    \"drivers_name\", \"gp_name\", \"circuit_name\", \"date\"\n",
    "]\n",
    "\n",
    "X = df.drop(columns=[c for c in drop_now if c in df.columns], errors=\"ignore\")\n",
    "y = df[\"delta_s\"].astype(float)\n",
    "\n",
    "# Choose categorical vs numeric\n",
    "cat_cols = []\n",
    "if \"country\" in X.columns:\n",
    "    cat_cols.append(\"country\")\n",
    "\n",
    "# safe numerics = all numeric except the target\n",
    "num_cols = [c for c in X.columns if c != \"delta_s\" and pd.api.types.is_numeric_dtype(X[c])]\n",
    "\n",
    "# Remove any remaining columns that equal y (just in case)\n",
    "num_cols = [c for c in num_cols if c != \"delta_s\"]\n",
    "\n",
    "# Build preprocessing\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols),\n",
    "        (\"num\", \"passthrough\", num_cols),\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    ")\n",
    "\n",
    "# Split (simple holdout; later we can do GroupKFold per race)\n",
    "X_model = X[cat_cols + num_cols].copy()\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_model, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "rf = RandomForestRegressor(\n",
    "    n_estimators=400,\n",
    "    max_depth=None,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "pipe = Pipeline(steps=[(\"pre\", preprocess), (\"rf\", rf)])\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "pred = pipe.predict(X_test)\n",
    "r2   = r2_score(y_test, pred)\n",
    "mae  = mean_absolute_error(y_test, pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, pred))\n",
    "\n",
    "print(\"\\n=== Historical Model (no leakage) ===\")\n",
    "print(f\"R²   : {r2:0.3f}\")\n",
    "print(f\"MAE  : {mae:0.3f} s (gap to fastest)\")\n",
    "print(f\"RMSE : {rmse:0.3f} s (gap to fastest)\")\n",
    "\n",
    "MODEL_OUT.parent.mkdir(parents=True, exist_ok=True)\n",
    "joblib.dump(pipe, MODEL_OUT)\n",
    "print(f\"\\n✅ Saved model -> {MODEL_OUT}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c58f2ec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hetan\\AppData\\Local\\Temp\\ipykernel_8444\\837888647.py:18: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[c] = pd.to_numeric(df[c], errors=\"ignore\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year  round  raceId  driverId\n",
      "0  1996      1     224        14\n",
      "1  1996      1     224        21\n",
      "2  1996      1     224        22\n",
      "3  1996      1     224        30\n",
      "4  1996      1     224        35\n",
      "5  1996      1     224        44\n",
      "6  1996      1     224        49\n",
      "7  1996      1     224        50\n",
      "rows: 11041 cols: 58\n",
      "    year  round  driverId  qual_best_s  drv_qual_mean_3  drv_qual_mean_5  \\\n",
      "0   1996      1        14       95.351              NaN              NaN   \n",
      "1   1996      1        21       95.898              NaN              NaN   \n",
      "2   1996      1        22       94.474              NaN              NaN   \n",
      "3   1996      1        30       93.125              NaN              NaN   \n",
      "4   1996      1        35       92.371              NaN              NaN   \n",
      "5   1996      1        44       95.330              NaN              NaN   \n",
      "6   1996      1        49       94.494              NaN              NaN   \n",
      "7   1996      1        50       95.338              NaN              NaN   \n",
      "8   1996      1        55       94.257              NaN              NaN   \n",
      "9   1996      1        56       92.889              NaN              NaN   \n",
      "10  1996      1        57       94.054              NaN              NaN   \n",
      "11  1996      1        63       94.832              NaN              NaN   \n",
      "\n",
      "    drv_qual_mean_10  drv_qual_std_3  drv_qual_std_5  drv_qual_std_10  \n",
      "0                NaN             NaN             NaN              NaN  \n",
      "1                NaN             NaN             NaN              NaN  \n",
      "2                NaN             NaN             NaN              NaN  \n",
      "3                NaN             NaN             NaN              NaN  \n",
      "4                NaN             NaN             NaN              NaN  \n",
      "5                NaN             NaN             NaN              NaN  \n",
      "6                NaN             NaN             NaN              NaN  \n",
      "7                NaN             NaN             NaN              NaN  \n",
      "8                NaN             NaN             NaN              NaN  \n",
      "9                NaN             NaN             NaN              NaN  \n",
      "10               NaN             NaN             NaN              NaN  \n",
      "11               NaN             NaN             NaN              NaN  \n",
      "saved temp to: f:\\Personal Projects\\F1-FastestLap-Predictor\\outputs\\f1_features_history_v2_temp.csv\n",
      "     year  round  qual_best_s  drv_qual_mean_3  drv_qual_std_3  \\\n",
      "0    1996      1       95.351              NaN             NaN   \n",
      "19   1996      2       80.167        95.351000             NaN   \n",
      "40   1996      3       92.001        87.759000       10.736709   \n",
      "62   1996      4       80.888        89.173000        7.977258   \n",
      "82   1996      5       87.688        84.352000        6.634031   \n",
      "103  1996      6       81.460        86.859000        5.602689   \n",
      "136  1996      8          NaN        83.345333        3.771719   \n",
      "158  1996      9          NaN        84.574000        4.403861   \n",
      "\n",
      "     drv_qual_mean_5  drv_qual_mean_10  \n",
      "0                NaN               NaN  \n",
      "19          95.35100         95.351000  \n",
      "40          87.75900         87.759000  \n",
      "62          89.17300         89.173000  \n",
      "82          87.10175         87.101750  \n",
      "103         87.21900         87.219000  \n",
      "136         84.44080         86.259167  \n",
      "158         85.50925         86.259167  \n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "ROOT = Path.cwd()\n",
    "if not (ROOT / \"outputs\").exists():\n",
    "    ROOT = ROOT.parent\n",
    "# 1) pick input/output paths\n",
    "IN_PATH  = ROOT / \"outputs\" / \"f1_features_history_v1.csv\"   # v1 file we already made\n",
    "OUT_PATH = ROOT / \"outputs\" / \"f1_features_history_v2_temp.csv\"  # temp file for this step\n",
    "\n",
    "# 2) load\n",
    "df = pd.read_csv(IN_PATH)\n",
    "\n",
    "# 3) ensure key columns are numeric where needed (helps sort)\n",
    "for c in [\"year\", \"round\", \"raceId\", \"driverId\", \"constructorId\"]:\n",
    "    if c in df.columns:\n",
    "        df[c] = pd.to_numeric(df[c], errors=\"ignore\")\n",
    "\n",
    "# 4) sort into season order (stable)\n",
    "df = df.sort_values(\n",
    "    by=[\"year\", \"round\", \"raceId\", \"driverId\"],\n",
    "    kind=\"mergesort\"\n",
    ").reset_index(drop=True)\n",
    "\n",
    "# quick sanity check\n",
    "print(df[[\"year\",\"round\",\"raceId\",\"driverId\"]].head(8))\n",
    "print(\"rows:\", len(df), \"cols:\", len(df.columns))\n",
    "\n",
    "\n",
    "\n",
    "WINS = (3, 5, 10)\n",
    "\n",
    "def add_drv_qual_rollups(frame: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Create drv_qual_mean_{w} and drv_qual_std_{w} using past (shifted) qual_best_s\n",
    "    within each (driverId, year) group.\n",
    "    \"\"\"\n",
    "    if \"qual_best_s\" not in frame.columns:\n",
    "        print(\"WARN: 'qual_best_s' missing; skipping driver qualifying rollups\")\n",
    "        return frame\n",
    "\n",
    "    # 0) ensure sort is correct inside each group (idempotent if you ran Step 1)\n",
    "    frame = frame.sort_values([\"year\",\"round\",\"raceId\",\"driverId\"], kind=\"mergesort\")\n",
    "\n",
    "    # 1) compute past-only values per (driverId, year)\n",
    "    past = frame.groupby([\"driverId\", \"year\"], sort=False)[\"qual_best_s\"].shift(1)\n",
    "\n",
    "    # 2) rolling stats per (driverId, year)\n",
    "    #    We re-group 'past' to keep windows inside each driver-year block.\n",
    "    g = past.groupby([frame[\"driverId\"], frame[\"year\"]])\n",
    "\n",
    "    for w in WINS:\n",
    "        frame[f\"drv_qual_mean_{w}\"] = g.apply(lambda s: s.rolling(w, min_periods=1).mean()).reset_index(level=[0,1], drop=True)\n",
    "        frame[f\"drv_qual_std_{w}\"]  = g.apply(lambda s: s.rolling(w, min_periods=1).std()).reset_index(level=[0,1], drop=True)\n",
    "\n",
    "    # Optional gentle fill for early-rows std (single prior → NaN). Comment out if you’d rather leave NaNs.\n",
    "    # std_cols = [f\"drv_qual_std_{w}\" for w in WINS]\n",
    "    # frame[std_cols] = frame[std_cols].fillna(0.0)\n",
    "\n",
    "    return frame\n",
    "\n",
    "df = add_drv_qual_rollups(df)\n",
    "\n",
    "# peek: a few rows to confirm values evolve only from *previous* races\n",
    "cols_to_show = (\n",
    "    [\"year\",\"round\",\"driverId\",\"qual_best_s\"]\n",
    "    + [f\"drv_qual_mean_{w}\" for w in WINS]\n",
    "    + [f\"drv_qual_std_{w}\" for w in WINS]\n",
    ")\n",
    "print(df[cols_to_show].head(12))\n",
    "\n",
    "# (mini-checkpoint) save temp so we don’t lose progress\n",
    "df.to_csv(OUT_PATH, index=False)\n",
    "print(\"saved temp to:\", OUT_PATH)\n",
    "\n",
    "d0 = int(df[\"driverId\"].iloc[0])   # pick any driver id that exists\n",
    "y0 = int(df[\"year\"].min())         # earliest season in your data\n",
    "cols = [\"year\",\"round\",\"qual_best_s\",\"drv_qual_mean_3\",\"drv_qual_std_3\",\n",
    "        \"drv_qual_mean_5\",\"drv_qual_mean_10\"]\n",
    "print(df[(df.driverId==d0) & (df.year==y0)][cols].head(8))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "110fb1d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    year  round  driverId  constructorId  qual_best_s  delta_to_pole  \\\n",
      "0   1996      1        14              1       95.351          2.980   \n",
      "1   1996      1        21             18       95.898          3.527   \n",
      "2   1996      1        22             17       94.474          2.103   \n",
      "3   1996      1        30              6       93.125          0.754   \n",
      "4   1996      1        35              3       92.371          0.000   \n",
      "5   1996      1        44             27       95.330          2.959   \n",
      "6   1996      1        49             15       94.494          2.123   \n",
      "7   1996      1        50             29       95.338          2.967   \n",
      "8   1996      1        55             22       94.257          1.886   \n",
      "9   1996      1        56              6       92.889          0.518   \n",
      "10  1996      1        57              1       94.054          1.683   \n",
      "11  1996      1        63             25       94.832          2.461   \n",
      "\n",
      "    driver_team_changed  drv_d2p_mean_3  drv_d2p_ewm_h3  team_d2p_mean_3  \\\n",
      "0                  True             NaN             NaN              NaN   \n",
      "1                  True             NaN             NaN              NaN   \n",
      "2                  True             NaN             NaN              NaN   \n",
      "3                  True             NaN             NaN              NaN   \n",
      "4                  True             NaN             NaN              NaN   \n",
      "5                  True             NaN             NaN              NaN   \n",
      "6                  True             NaN             NaN              NaN   \n",
      "7                  True             NaN             NaN              NaN   \n",
      "8                  True             NaN             NaN              NaN   \n",
      "9                  True             NaN             NaN           0.2262   \n",
      "10                 True             NaN             NaN           0.8940   \n",
      "11                 True             NaN             NaN              NaN   \n",
      "\n",
      "    team_d2p_ewm_h3  \n",
      "0               NaN  \n",
      "1               NaN  \n",
      "2               NaN  \n",
      "3               NaN  \n",
      "4               NaN  \n",
      "5               NaN  \n",
      "6               NaN  \n",
      "7               NaN  \n",
      "8               NaN  \n",
      "9            0.2262  \n",
      "10           0.8940  \n",
      "11              NaN  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# -----------------------------\n",
    "# Configurable knobs (you can tune later)\n",
    "# -----------------------------\n",
    "SEASON_DECAY       = 0.95   # mild decay at any season boundary\n",
    "REGULATION_DECAY   = 0.80   # extra decay in big-reg years\n",
    "TEAM_SWITCH_DECAY  = 0.30   # keep 30% of prior team form when driver changes team\n",
    "REGULATION_YEARS   = {2014, 2017, 2022}  # major resets; extend if desired\n",
    "\n",
    "# -----------------------------\n",
    "# 3.0 Order rows strictly (WHY: history walks row order)\n",
    "# -----------------------------\n",
    "df = df.sort_values([\"year\",\"round\",\"raceId\",\"driverId\"], kind=\"mergesort\").reset_index(drop=True)\n",
    "\n",
    "# -----------------------------\n",
    "# 3.1 Normalize quali pace by weekend (delta_to_pole)\n",
    "# -----------------------------\n",
    "pole_best = df.groupby([\"year\",\"round\"])[\"qual_best_s\"].transform(\"min\")     # aligned column\n",
    "df[\"delta_to_pole\"] = df[\"qual_best_s\"] - pole_best                           # 0 for pole sitter\n",
    "\n",
    "# -----------------------------\n",
    "# 3.2 Helper: per-row decay multiplier at season boundaries (for carry-over)\n",
    "# -----------------------------\n",
    "def boundary_decay_per_row(year_series: pd.Series) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Returns a multiplicative decay vector aligned to the input series:\n",
    "    - 1.0 within a season\n",
    "    - *= SEASON_DECAY at a season rollover\n",
    "    - *= REGULATION_DECAY extra if new season is a regulation year\n",
    "    \"\"\"\n",
    "    y = year_series.to_numpy()\n",
    "    b = np.ones_like(y, dtype=float)\n",
    "\n",
    "    # boundary iff current year != previous row's year (within the grouping we'll apply on)\n",
    "    boundary = np.zeros_like(y, dtype=bool)\n",
    "    boundary[1:] = (y[1:] != y[:-1])\n",
    "\n",
    "    # base season decay\n",
    "    b[boundary] *= SEASON_DECAY\n",
    "\n",
    "    # extra reg decay when ENTERING a big-reg year\n",
    "    reg_boundary = np.zeros_like(y, dtype=bool)\n",
    "    reg_boundary[1:] = boundary[1:] & np.isin(y[1:], list(REGULATION_YEARS))\n",
    "    b[reg_boundary] *= REGULATION_DECAY\n",
    "\n",
    "    return pd.Series(b, index=year_series.index)\n",
    "\n",
    "# ==========================================================\n",
    "# DRIVER FORM (carry across seasons; mild boundary decay; no team-switch penalty)\n",
    "# ==========================================================\n",
    "# 3.3 Shift BEFORE rolling (no-leak rule)\n",
    "drv_past = df.groupby(\"driverId\", sort=False)[\"delta_to_pole\"].shift(1)\n",
    "\n",
    "# 3.4 Season-boundary decay per driver (applied to past values)\n",
    "drv_decay = df.groupby(\"driverId\", sort=False)[\"year\"].transform(boundary_decay_per_row).astype(float)\n",
    "drv_past_decayed = drv_past * drv_decay\n",
    "\n",
    "# 3.5 Rolling stats across seasons (group by driver only)\n",
    "g_drv = drv_past_decayed.groupby(df[\"driverId\"])\n",
    "\n",
    "for w in (3, 5, 10):\n",
    "    df[f\"drv_d2p_mean_{w}\"] = g_drv.transform(lambda s: s.rolling(w, min_periods=1).mean())\n",
    "    df[f\"drv_d2p_std_{w}\"]  = g_drv.transform(lambda s: s.rolling(w, min_periods=2).std())\n",
    "\n",
    "# EWMA (smooth momentum)\n",
    "df[\"drv_d2p_ewm_h3\"] = g_drv.transform(lambda s: s.ewm(halflife=3, adjust=False).mean())\n",
    "\n",
    "# ==========================================================\n",
    "# TEAM FORM (carry across seasons; boundary decay; STRONG penalty on team switches)\n",
    "# ==========================================================\n",
    "# 3.6 Detect team changes per driver (True when constructorId != previous race)\n",
    "df[\"driver_team_changed\"] = (\n",
    "    df.groupby(\"driverId\")[\"constructorId\"].transform(lambda s: s != s.shift(1))\n",
    ")\n",
    "\n",
    "# 3.7 Shift team pace BEFORE rolling (no leak); carry by constructorId across seasons\n",
    "team_past = df.groupby(\"constructorId\", sort=False)[\"delta_to_pole\"].shift(1)\n",
    "\n",
    "# 3.8 Base season/reg decay per constructor\n",
    "team_decay_base = df.groupby(\"constructorId\", sort=False)[\"year\"].transform(boundary_decay_per_row).astype(float)\n",
    "\n",
    "# 3.9 Apply extra decay when a driver switches teams (the *team* history becomes less relevant to this row)\n",
    "# Note: we multiply a row-wise factor; where switch happened, shrink the contribution of previous team form.\n",
    "team_decay = team_decay_base.copy()\n",
    "team_decay[df[\"driver_team_changed\"]] *= TEAM_SWITCH_DECAY\n",
    "\n",
    "team_past_decayed = team_past * team_decay\n",
    "g_team = team_past_decayed.groupby(df[\"constructorId\"])\n",
    "\n",
    "for w in (3, 5, 10):\n",
    "    df[f\"team_d2p_mean_{w}\"] = g_team.transform(lambda s: s.rolling(w, min_periods=1).mean())\n",
    "    df[f\"team_d2p_std_{w}\"]  = g_team.transform(lambda s: s.rolling(w, min_periods=2).std())\n",
    "\n",
    "df[\"team_d2p_ewm_h3\"] = g_team.transform(lambda s: s.ewm(halflife=3, adjust=False).mean())\n",
    "\n",
    "# -----------------------------\n",
    "# 3.10 Quick peek\n",
    "# -----------------------------\n",
    "cols = [\n",
    "    \"year\",\"round\",\"driverId\",\"constructorId\",\"qual_best_s\",\"delta_to_pole\",\n",
    "    \"driver_team_changed\",\n",
    "    \"drv_d2p_mean_3\",\"drv_d2p_ewm_h3\",\"team_d2p_mean_3\",\"team_d2p_ewm_h3\"\n",
    "]\n",
    "print(df[cols].head(12))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
